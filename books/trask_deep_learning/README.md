# Grokking Deep Learning
By Andrew Trask

# Tables of Contents
## 1. Introduction 
- Just need basic math and programming knowledge. Goal is to be as simple as possible with lots of practical coding examples

## 2. Fundamental Concepts: How do machines learn?
- Supervised vs Unsupervised models
  - **Supervised**: learns to transform one dataset (input) into another dataset (output) using labeled data
  - **Unsupervised**: Typically groups data, looks for patterns
- Parametric vs nonparametric learning
  - **Parametric**: fixed number of parameters
  - **Non-parametric**: number of parameters varys with the input data, not fixed and can grow

## 3. Introduction to neural prediciton: forward propogation
- Basic Neural Network architectures and concepts with single input/output, multi input/output, and multiple layer NNs
- **Forward Propogation**: Process of passing activations forward in a network. Used to make predictions.
  - input data -> input layer -> hidden layers -> output

## 4. Introduction to neural learning: gradient descent

## 5. Learning multiple weights at a time: generalizing gradient descent

## 6. Building your first deep neural network: introduction to backpropogation

## 7. How to picture neural networks: in your head and on paper

## 8. Learning signal and ignoring noise: introduction to regularization and batching

## 9. Modeling probabilities and nonlinearities: activation functions

## 10. Neural Learning about edges and conrners: intro to convolutional neural networks

## 11. Neural networks that understand language: king - man + woman == ?

## 12. Neural netowrks that write like shakespeare: recurrent layers for variable-length data

## 13. Introducing automatic optimization

## 14. Learning to write like shakespeare: long short-term memory

## 15. Deep learning on unseen data: introducing federated learning

## 16. Where to go from here:
